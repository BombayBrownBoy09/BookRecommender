# -*- coding: utf-8 -*-
"""BooksRec.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RWn7F8-CF5S1oB8IHTQ-u68K_qWl_wgV
"""

cd /content/drive/MyDrive/bookRecommendation

"""**Count the number of lines using wc**"""

!wc -l goodreads_books.json.gz

!ls -lh | grep goodreads_books.json.gz

# Read line by line since the file is very large
import gzip

with gzip.open("goodreads_books.json.gz") as f:
    line = f.readline()

line

# load json using python
import json

data = json.loads(line)
data

"""Parse book metadata"""

# Extract only the fileds which are rewuired from the json
def parse_fields(line):
    data = json.loads(line)
    return {
        "book_id": data["book_id"], 
        "title": data["title_without_series"], 
        "ratings": data["ratings_count"], 
        "url": data["url"], 
        "cover_image": data["image_url"]
    }

# go line by line and parse each line
books_titles = []
with gzip.open("goodreads_books.json.gz") as f:
    while True:
        line = f.readline()
        if not line:
            break
        fields = parse_fields(line)
        try:
            ratings = int(fields["ratings"])
        except ValueError:
            continue
        # Only take books with more than 15 ratings to reduce the corpus
        if ratings > 15:
            books_titles.append(fields)

"""Process the metadata"""

import pandas as pd

titles = pd.DataFrame.from_dict(books_titles)
titles["ratings"] = pd.to_numeric(titles["ratings"])
titles["mod_title"] = titles["title"].str.replace("[^a-zA-Z0-9 ]", "", regex=True)
titles["mod_title"] = titles["mod_title"].str.lower()
titles["mod_title"] = titles["mod_title"].str.replace("\s+", " ", regex=True)
titles = titles[titles["mod_title"].str.len() > 0]
titles.to_json("books_titles.json")

titles

"""Build Search engine by using TF-IDF matrix and cosine similarity"""

# Search engine queries modified titles
from sklearn.feature_extraction.text import TfidfVectorizer
vectorizer = TfidfVectorizer()

tfidf = vectorizer.fit_transform(titles["mod_title"])

# turn search query into vector and match it with the matrix
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import re

def make_clickable(val):
    return '<a target="_blank" href="{}">Goodreads</a>'.format(val, val)

def show_image(val):
    return '<a href="{}"><img src="{}" width=50></img></a>'.format(val, val)

def search(query,vectorizer):
    processed = re.sub("[^a-zA-Z0-9 ]", "", query.lower())
    query_vec = vectorizer.transform([query])
    similarity = cosine_similarity(query_vec, tfidf).flatten()
    # find indices of 10 largest similarity values
    indices = np.argpartition(similarity, -10)[-10:]
    results = titles.iloc[indices]
    results = results.sort_values("ratings", ascending=False)
    
    return results.head(5).style.format({'url': make_clickable, 'cover_image': show_image})

search("sherlock holmes", vectorizer)

"""
Create list of liked books"""

liked_books = ['22543496', '39661', '12816830', '482060', "9401317", "9317691", "8153988"]

!head book_id_map.csv

# form a dictionary of books where key is csv id from interactions and value is book id from json
csv_book_mapping = {}

with open("book_id_map.csv", "r") as f:
    while True:
        line = f.readline()
        if not line:
            break
        csv_id, book_id = line.strip().split(",")
        csv_book_mapping[csv_id] = book_id

len(csv_book_mapping)

csv_book_mapping['0']

# count no. of lines interaction data
!wc -l goodreads_interactions.csv

!ls -lh | grep goodreads_interactions.csv

"""Find users who like same books as us"""

!head goodreads_interactions.csv

overlap_users = set()

with open("goodreads_interactions.csv", 'r') as f:
    while True:
        line = f.readline()
        if not line:
            break
        user_id, csv_id, _, rating, _ = line.split(",")
        
        if user_id in overlap_users:
            continue

        try:
            rating = int(rating)
        except ValueError:
            continue
        
        #convert csvid to book id
        book_id = csv_book_mapping[csv_id]
        
        # if the booke id is in our liked books, add the user to the list of overlapped users
        if book_id in liked_books and rating >= 4:
                overlap_users.add(user_id)

# Find books which the overlapped users have read
# reclines contains potential books we want to read
rec_lines = []

with open("goodreads_interactions.csv", 'r') as f:
    while True:
        line = f.readline()
        if not line:
            break
        user_id, csv_id, _, rating, _ = line.split(",")
        
        if user_id in overlap_users:
            book_id = csv_book_mapping[csv_id]
            rec_lines.append([user_id, book_id, rating])



#rank recommendations(books) in the rec_line
import pandas as pd

recs = pd.DataFrame(rec_lines, columns=["user_id", "book_id", "rating"])
recs["book_id"] = recs["book_id"].astype(str)

recs

# Find the books with most ratings
top_recs = recs["book_id"].value_counts().head(10)

top_recs = top_recs.index.values

books_titles = pd.read_json("books_titles.json")
books_titles["book_id"] = books_titles["book_id"].astype(str)

books_titles.head()

books_titles[books_titles["book_id"].isin(top_recs)]

# find books that are more popular among users like us
all_recs = recs["book_id"].value_counts()

all_recs = all_recs.to_frame().reset_index()
all_recs.columns = ["book_id", "book_count"]

all_recs.head(5)

all_recs = all_recs.merge(books_titles, how="inner", on="book_id")

# Assign a score to compare each book( If a book is more popular among our set and less popular on goodreads
#it is going to be recommended)
# looking for books that are popular among users like us but not necessarily on all of goodreads
all_recs["score"] = all_recs["book_count"] * (all_recs["book_count"] / all_recs["ratings"])

all_recs.sort_values("score", ascending=False).head(10)

all_recs[all_recs["book_count"] > 200].sort_values("score", ascending=False).head(10)

popular_recs = all_recs[all_recs["book_count"] > 200].sort_values("score", ascending=False)

def make_clickable(val):
    return '<a target="_blank" href="{}">Goodreads</a>'.format(val, val)

def show_image(val):
    return '<a href="{}"><img src="{}" width=50></img></a>'.format(val, val)


popular_recs[~popular_recs["book_id"].isin(liked_books)].head(10).style.format({'url': make_clickable, 'cover_image': show_image})